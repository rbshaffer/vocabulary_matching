{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import ontospy\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_list = stopwords.words('english')\n",
    "\n",
    "with open('data/thesaurus.json', 'r') as f:\n",
    "    thesaurus = json.loads(f.read())\n",
    "    thesaurus = thesaurus[0]\n",
    "    \n",
    "constitute = ontospy.Ontospy('data/ontology.owl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# some functions to help manipulate the Constitute ontology\n",
    "\n",
    "def build_constitute_edgelist(node, edgelist=[]):\n",
    "    parent_lab = str(node.uri).split('/')[-1]\n",
    "    children = node.children()\n",
    "    \n",
    "    for child in children:\n",
    "        child_lab = str(child.uri).split('/')[-1]\n",
    "        edgelist.append([parent_lab, child_lab])\n",
    "        edgelist = build_constitute_edgelist(child, edgelist)\n",
    "        \n",
    "    \n",
    "    return edgelist\n",
    "\n",
    "def build_constitute_node_dic(node, node_dic={}):\n",
    "    parent_lab = str(node.uri).split('/')[-1]\n",
    "    if parent_lab not in node_dic:\n",
    "        node_dic[parent_lab] = node.uri\n",
    "        \n",
    "    children = node.children()\n",
    "    \n",
    "    for child in children:\n",
    "        node_dic = build_constitute_node_dic(child, node_dic)\n",
    "        \n",
    "    return node_dic\n",
    "\n",
    "def build_constitute_label_dic(node, label_dic={}):\n",
    "    node_label = constitute.getEntity(uri=node.uri).bestLabel().strip()\n",
    "    node_label = ' '.join([w for w in node_label.lower().split() \n",
    "                           if w not in stop_list])\n",
    "    if node_label not in label_dic:\n",
    "        label_dic[node_label] = node.uri\n",
    "        \n",
    "    children = node.children()\n",
    "    \n",
    "    for child in children:\n",
    "        label_dic = build_constitute_label_dic(child, label_dic)\n",
    "        \n",
    "    return label_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some functions to manipulate the Venice thesaurus\n",
    "def build_thesaurus_node_dic(node, node_dic={}):\n",
    "    parent_lab = node.get('label')\n",
    "    \n",
    "    if parent_lab and parent_lab not in node_dic:\n",
    "        parent_lab = re.sub('\\<IT[-+]\\>', '', parent_lab)\n",
    "        parent_lab = ' '.join([w for w in parent_lab.lower().split() \n",
    "                               if w not in stop_list])\n",
    "        node_dic[parent_lab] = {'id': node['id'], 'synonyms': node['synonyms']}\n",
    "    \n",
    "    for child in node['nodes']:\n",
    "        node_dic = build_thesaurus_node_dic(child, node_dic)\n",
    "        \n",
    "    return node_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class to try out various matching approaches\n",
    "\n",
    "# base class\n",
    "class MatchBase:\n",
    "    def __init__(self, reference, word2vec_dir = None):\n",
    "        import gensim\n",
    "        self.ref_list = reference\n",
    "        \n",
    "        if word2vec_dir:\n",
    "            self.word2vec_mod = gensim.models.Word2Vec.load(word2vec_dir)\n",
    "            \n",
    "        else:\n",
    "            self.word2vec_mod = None\n",
    "            \n",
    "    def _preprocess(self, term):\n",
    "        import string\n",
    "        \n",
    "        term = re.sub('[' + string.punctuation + ']', '', term)\n",
    "        term = term.lower()\n",
    "        \n",
    "        return term\n",
    "\n",
    "# matching on the node variable name\n",
    "class NodeMatch(MatchBase):\n",
    "    def str_match(self, word):\n",
    "        # just look for simple equality between node IDs (after preprocessing)\n",
    "        word = self._preprocess(word)\n",
    "        preprocessed_ref = [self._preprocess(ref) for ref in self.ref_list]\n",
    "        \n",
    "        matches = [ref for ref in preprocessed_ref if ref == word]\n",
    "        \n",
    "        return matches\n",
    "    \n",
    "    def word2vec_match(self, word, cutoff=0.5):\n",
    "        # use a pretrained word2vec model to calculate similarity\n",
    "        # treat all values over cutoff as a match\n",
    "        \n",
    "        if not self.word2vec_mod:\n",
    "            print('Be sure to load a word2vec model before using this function!')\n",
    "        else:\n",
    "            word = self._preprocess(word)\n",
    "            preprocessed_ref = [self._preprocess(ref) for ref in self.ref_list]\n",
    "            \n",
    "            sims = {}\n",
    "            \n",
    "            for ref in preprocessed_ref:\n",
    "                try:\n",
    "                    sims[ref] = self.word2vec_mod.similarity(ref, word)\n",
    "                except:\n",
    "                    sims[ref] = None\n",
    "            \n",
    "            sims = {s: sims[s] for s in sims if sims[s] and sims[s] > cutoff}\n",
    "            return sims\n",
    "        \n",
    "# matching on plain-text label\n",
    "class LabelMatch(MatchBase):\n",
    "    def word2vec_match(self, word, cutoff=0.9):\n",
    "        # use a pretrained word2vec model to generate vectors for labels and terms\n",
    "        # for multiword labels/terms, sum vectors for each term (not a great solution, but ok for testing)\n",
    "        # treat all values over cutoff as a match\n",
    "        \n",
    "        from scipy.spatial.distance import cosine\n",
    "    \n",
    "        if not self.word2vec_mod:\n",
    "            print('Be sure to load a word2vec model before using this function!')\n",
    "        else:\n",
    "            preprocessed_word = self._preprocess(word)\n",
    "            summed_word_vec = sum([self.word2vec_mod[w] for w in preprocessed_word.split()\n",
    "                                   if w in self.word2vec_mod])\n",
    "            \n",
    "            # sum() casts None to 0\n",
    "            # so, checking for int is a hack to make sure at least one token in the word was in the word2vec vocab\n",
    "            if type(summed_word_vec) != int:\n",
    "                ref_vectors = {}\n",
    "                for ref in self.ref_list:\n",
    "                    preprocessed_ref = self._preprocess(ref)\n",
    "                    summed_label = sum([self.word2vec_mod[w] for w in preprocessed_ref.split() \n",
    "                                        if w in self.word2vec_mod])\n",
    "                    \n",
    "                    # see above\n",
    "                    if type(summed_label) != int:\n",
    "                        ref_vectors[ref] = summed_label\n",
    "\n",
    "                # note cosine = distance, not similarity w/ scipy\n",
    "                sims = {ref: 1 - cosine(summed_word_vec, ref_vectors[ref]) for ref in ref_vectors}\n",
    "\n",
    "                sims = {ref: sims[ref] for ref in sims if sims[ref] > cutoff}\n",
    "            \n",
    "                return sims\n",
    "            \n",
    "            else:\n",
    "                return {}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build the various helper dictionaries\n",
    "constitute_base_node = constitute.getClass('/Topics')[0]\n",
    "constitute_nodes = build_constitute_node_dic(constitute_base_node)\n",
    "constitute_labels = build_constitute_label_dic(constitute_base_node)\n",
    "\n",
    "# renaming node key in the top-level element to make recursion easier\n",
    "try:\n",
    "    thesaurus['nodes'] = thesaurus.pop('data')\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "thesaurus_nodes = build_thesaurus_node_dic(thesaurus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run the two nodematch approaches\n",
    "node_match = NodeMatch(constitute_nodes, 'data/word2vec_model_200_no_stem.pydata')\n",
    "\n",
    "str_matches = []\n",
    "word2vec_node_matches = {}\n",
    "for node in thesaurus_nodes:\n",
    "    str_matches += node_match.str_match(node)\n",
    "\n",
    "    word2vec_match = node_match.word2vec_match(node)\n",
    "    if word2vec_match:\n",
    "        word2vec_node_matches[node] = word2vec_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flag',\n",
       " 'immunity',\n",
       " 'evidence',\n",
       " 'religion',\n",
       " 'motto',\n",
       " 'budget',\n",
       " 'elections',\n",
       " 'finance',\n",
       " 'quorum',\n",
       " 'executive',\n",
       " 'press',\n",
       " 'legislation',\n",
       " 'language',\n",
       " 'opinion']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple string match on node variable names works, but very limiting\n",
    "str_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 39\n",
      "--------\n",
      "admissibility {'jury': 0.50002017610264649}\n",
      "\n",
      "\n",
      "subsidiarity {'artists': 0.58169680661190515, 'leisure': 0.5057359604314462}\n",
      "\n",
      "\n",
      "opinion {'opinion': 1.0}\n",
      "\n",
      "\n",
      "motto {'motto': 0.99999999999999989, 'flag': 0.55580798315594293, 'anthem': 0.56877491481239872}\n",
      "\n",
      "\n",
      "proportionality {'artists': 0.54255512659428107}\n",
      "\n",
      "\n",
      "press {'press': 0.99999999999999978}\n",
      "\n",
      "\n",
      "foreigners {'slave': 0.54842999886666566, 'artists': 0.51293563607890402, 'asylum': 0.52807246732580326}\n",
      "\n",
      "\n",
      "finance {'finance': 0.99999999999999978}\n",
      "\n",
      "\n",
      "equality {'equal': 0.51332090408235009, 'dignity': 0.50960294834118935}\n",
      "\n",
      "\n",
      "race {'religion': 0.64135900807386692}\n",
      "\n",
      "\n",
      "correspondence {'privacy': 0.73245220338826944}\n",
      "\n",
      "\n",
      "flag {'motto': 0.55580798315594293, 'anthem': 0.84562744610617557, 'arms': 0.54487966301844304, 'flag': 1.0}\n",
      "\n",
      "\n",
      "executive {'executive': 1.0}\n",
      "\n",
      "\n",
      "equity {'artists': 0.55882544590066585, 'leisure': 0.51139734863407682}\n",
      "\n",
      "\n",
      "descent {'citizenship': 0.51500973580595866}\n",
      "\n",
      "\n",
      "characteristics {'solid': 0.52293000243150789, 'shelter': 0.51018075756195369, 'artists': 0.60917408099020354, 'leisure': 0.53072226367276587}\n",
      "\n",
      "\n",
      "budget {'budget': 0.99999999999999967}\n",
      "\n",
      "\n",
      "elections {'elections': 1.0000000000000002}\n",
      "\n",
      "\n",
      "sessions {'session': 0.72443373048092163}\n",
      "\n",
      "\n",
      "types {'cruelty': 0.54051006852367023, 'artists': 0.54955843979581276}\n",
      "\n",
      "\n",
      "legislation {'legislation': 1.0}\n",
      "\n",
      "\n",
      "language {'language': 1.0, 'religion': 0.50396666816307301}\n",
      "\n",
      "\n",
      "gender {'religion': 0.53510538839770427}\n",
      "\n",
      "\n",
      "universities {'artists': 0.57445536425797761, 'science': 0.51662112094278811}\n",
      "\n",
      "\n",
      "election {'elections': 0.64403200109000447}\n",
      "\n",
      "\n",
      "democracy {'dignity': 0.53929983623889455}\n",
      "\n",
      "\n",
      "religion {'language': 0.50396666816307301, 'religion': 1.0000000000000002}\n",
      "\n",
      "\n",
      "quorum {'quorum': 1.0}\n",
      "\n",
      "\n",
      "minors {'shelter': 0.57942234718381536, 'cruelty': 0.60806843932744281, 'artists': 0.63674318019057807, 'juvenile': 0.50801678725797683}\n",
      "\n",
      "\n",
      "sources {'solid': 0.52187535536213903, 'artists': 0.50256415038372437, 'income': 0.58208191228157891}\n",
      "\n",
      "\n",
      "opinions {'religion': 0.5335791064221963}\n",
      "\n",
      "\n",
      "evidence {'evidence': 1.0000000000000002}\n",
      "\n",
      "\n",
      "languages {'language': 0.66796884007939106}\n",
      "\n",
      "\n",
      "implementation {'enforcement': 0.51563595451804933}\n",
      "\n",
      "\n",
      "taxation {'tax': 0.55960877467954795}\n",
      "\n",
      "\n",
      "employment {'work': 0.50108377983374963}\n",
      "\n",
      "\n",
      "effects {'amparo': 0.51646438714801035}\n",
      "\n",
      "\n",
      "costs {'income': 0.51825770722997766}\n",
      "\n",
      "\n",
      "immunity {'immunity': 1.0}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# word2vec on variable names works, but only works for labels that are in-vocab (e.g. \"judcrts4\" won't work)\n",
    "# likely would perform better with a more broadly-trained model\n",
    "# cutoff value optimization?\n",
    "\n",
    "print('Number of matches:', len(word2vec_node_matches))\n",
    "print('--------')\n",
    "for node in word2vec_node_matches:\n",
    "    print(node, word2vec_node_matches[node])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run the label match approach\n",
    "label_match = LabelMatch(constitute_labels, 'data/word2vec_model_200_no_stem.pydata')\n",
    "\n",
    "word2vec_label_matches = {}\n",
    "for node in thesaurus_nodes:\n",
    "    word2vec_match = label_match.word2vec_match(node)\n",
    "    if word2vec_match:\n",
    "        word2vec_label_matches[node] = word2vec_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 65\n",
      "--------\n",
      "civil service {'civil service recruitment': 0.94226427866779272}\n",
      "\n",
      "\n",
      "civil political rights {'civil political rights': 0.99999989369019582}\n",
      "\n",
      "\n",
      "quasi-constitutional legislation {'legislation': 0.99999994125692659}\n",
      "\n",
      "\n",
      "right environment {'right safe work environment': 0.91217489702483723}\n",
      "\n",
      "\n",
      "central bank {'central bank': 1.000000023261278}\n",
      "\n",
      "\n",
      "trade unions {'right join trade unions': 0.92007532169831341}\n",
      "\n",
      "\n",
      "right self-determination {'right marry': 0.91258486410401041, 'right shelter': 0.90385679168888244}\n",
      "\n",
      "\n",
      "right health {'right health care': 0.92349120316468525}\n",
      "\n",
      "\n",
      "right petition {'right petition': 0.99999992146765215}\n",
      "\n",
      "\n",
      "right resistance {'right marry': 0.94103134171541181, 'right shelter': 0.91216643457469215, 'right amparo': 0.90405590407667591}\n",
      "\n",
      "\n",
      "supreme court {'supreme court': 1.0000000637617144, 'supreme court selection': 0.90037642165321397}\n",
      "\n",
      "\n",
      "executive {'executive': 0.99999994113039825}\n",
      "\n",
      "\n",
      "freedom association {'freedom association': 1.000000166888442}\n",
      "\n",
      "\n",
      "international treaties {'treaties': 0.92948876394574265}\n",
      "\n",
      "\n",
      "right examine witnesses {'right examine evidence/ witnesses': 0.94733626491754175}\n",
      "\n",
      "\n",
      "right development {'right development personality': 0.90342462170831683}\n",
      "\n",
      "\n",
      "freedom written press {'freedom press': 0.90249431599578667}\n",
      "\n",
      "\n",
      "administrative courts {'establishment administrative courts': 0.91558770698275971, 'administrative courts': 0.99999996484490739}\n",
      "\n",
      "\n",
      "freedom assembly {'freedom assembly': 1.0000001094100546}\n",
      "\n",
      "\n",
      "entitlement rights {'rights debtors': 0.96382324970093769}\n",
      "\n",
      "\n",
      "right strike {'right strike': 0.99999993770519069, 'right marry': 0.91039771227941346}\n",
      "\n",
      "\n",
      "prohibition torture inhuman degrading treatment {'prohibition cruel treatment': 0.95014195136443613}\n",
      "\n",
      "\n",
      "citizenship nationality {'citizenship': 0.90438755679417837}\n",
      "\n",
      "\n",
      "treaties constitutions {'treaties': 0.93958524651504238}\n",
      "\n",
      "\n",
      "non-derogable rights {'rights debtors': 0.98549017657511451}\n",
      "\n",
      "\n",
      "right counsel {'right counsel': 0.99999997491444537}\n",
      "\n",
      "\n",
      "freedom worship {'freedom opinion/thought/conscience': 0.90223843509714552}\n",
      "\n",
      "\n",
      "ombudsman {'ombudsman': 0.99999992274859917}\n",
      "\n",
      "\n",
      "structure state {'structure state': 1.0000000310093942}\n",
      "\n",
      "\n",
      "freedom movement {'freedom movement': 1.0000001286855218}\n",
      "\n",
      "\n",
      "language {'language': 1.0000000800361104}\n",
      "\n",
      "\n",
      "campaign financing {'campaign financing': 0.99999999655654837}\n",
      "\n",
      "\n",
      "right incriminate oneself {'right marry': 0.94594654827362179, 'right shelter': 0.90158657426399447}\n",
      "\n",
      "\n",
      "freedom teach {'freedom opinion/thought/conscience': 0.97285506106455188}\n",
      "\n",
      "\n",
      "right work {'right work': 1.0000000169463568}\n",
      "\n",
      "\n",
      "right life {'right life': 1.0000000810860978}\n",
      "\n",
      "\n",
      "national emblem {'national anthem': 0.91034108175094819}\n",
      "\n",
      "\n",
      "military courts {'establishment military courts': 0.92041654379391458}\n",
      "\n",
      "\n",
      "right culture {'right culture': 1.0000001090651252}\n",
      "\n",
      "\n",
      "head state {'head state': 0.99999989230087771, 'eligibility head state': 0.91231681067951509, 'head state replacement': 0.95024355549548323}\n",
      "\n",
      "\n",
      "secret ballot {'secret ballot': 1.0000000570994394}\n",
      "\n",
      "\n",
      "national anthem {'national anthem': 1.0000000285995287, 'national flag': 0.93151134405630442}\n",
      "\n",
      "\n",
      "consumer protection {'protection self-incrimination': 0.92482459727739219, 'protection consumers': 0.94136535741253602}\n",
      "\n",
      "\n",
      "freedom expression {'freedom expression': 1.0000000009634518, 'freedom opinion/thought/conscience': 0.91228452718310071, 'freedom press': 0.90749126507625988}\n",
      "\n",
      "\n",
      "right family life {'right life': 0.92700445014954647}\n",
      "\n",
      "\n",
      "race {'race ethnicity': 0.97926890412291756}\n",
      "\n",
      "\n",
      "conclusion treaties {'treaties': 0.92913688821803875}\n",
      "\n",
      "\n",
      "freedom conscience {'freedom expression': 0.90713238863157086, 'freedom opinion/thought/conscience': 0.91090886240614033}\n",
      "\n",
      "\n",
      "elections {'elections': 0.99999986920196748, 'scheduling elections': 0.99999986920196748}\n",
      "\n",
      "\n",
      "right intellectual property {'right property': 0.916116532247226}\n",
      "\n",
      "\n",
      "religion {'religion': 1.0000000508991531}\n",
      "\n",
      "\n",
      "basic principles {'basic principles': 1.0000000079516849}\n",
      "\n",
      "\n",
      "right property {'right property': 0.99999997847148314}\n",
      "\n",
      "\n",
      "legislation {'legislation': 0.99999994125692659}\n",
      "\n",
      "\n",
      "ordinary courts {'ordinary courts': 1.0000001456895935}\n",
      "\n",
      "\n",
      "banning political parties {'preferred political parties': 0.98159481404626348, 'political parties': 0.99999993103685325, 'prohibited political parties': 0.91217097770310263}\n",
      "\n",
      "\n",
      "political parties {'preferred political parties': 0.98159481404626348, 'political parties': 0.99999993103685325, 'prohibited political parties': 0.91217097770310263}\n",
      "\n",
      "\n",
      "right housing {'right shelter': 0.93731378250352237}\n",
      "\n",
      "\n",
      "state symbols {'state definition symbols': 0.92562165104483984}\n",
      "\n",
      "\n",
      "law-making procedure {'veto override procedure': 0.90854767994737906}\n",
      "\n",
      "\n",
      "right citizenship nationality {'right renounce citizenship': 0.91834059546328883}\n",
      "\n",
      "\n",
      "right emigrate {'right strike': 0.90549851432769213, 'right marry': 0.96275043748076017, 'right shelter': 0.91733310727225592, 'right amparo': 0.9022759535132705}\n",
      "\n",
      "\n",
      "immunity {'immunity legislators': 0.92403345917743596}\n",
      "\n",
      "\n",
      "european central bank {'central bank': 0.91301416194193485}\n",
      "\n",
      "\n",
      "right information {'right information': 0.99999985889701581}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Not bad, though still not a ton of matches\n",
    "# again, cutoff optimization?\n",
    "\n",
    "print('Number of matches:', len(word2vec_label_matches))\n",
    "print('--------')\n",
    "for label in word2vec_label_matches:\n",
    "    print(label, word2vec_label_matches[label])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of overlaps: 7\n"
     ]
    }
   ],
   "source": [
    "# Interestingly, pretty different information in two word2vec approaches\n",
    "# combined, this gets ~10% of total\n",
    "print('Number of overlaps:', sum([k in word2vec_label_matches for k in word2vec_node_matches]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390\n",
      "708\n"
     ]
    }
   ],
   "source": [
    "print(len(constitute_nodes))\n",
    "print(len(thesaurus_nodes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
