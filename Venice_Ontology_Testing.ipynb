{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import ontospy\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('data/thesaurus.json', 'r') as f:\n",
    "    thesaurus = json.loads(f.read())\n",
    "    thesaurus = thesaurus[0]\n",
    "    \n",
    "constitute = ontospy.Ontospy('data/ontology.owl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# some functions to help manipulate the Constitute ontology\n",
    "\n",
    "def build_constitute_edgelist(node, edgelist=[]):\n",
    "    parent_lab = str(node.uri).split('/')[-1]\n",
    "    children = node.children()\n",
    "    \n",
    "    for child in children:\n",
    "        child_lab = str(child.uri).split('/')[-1]\n",
    "        edgelist.append([parent_lab, child_lab])\n",
    "        edgelist = build_constitute_edgelist(child, edgelist)\n",
    "        \n",
    "    \n",
    "    return edgelist\n",
    "\n",
    "def build_constitute_node_dic(node, node_dic={}):\n",
    "    parent_lab = str(node.uri).split('/')[-1]\n",
    "    if parent_lab not in node_dic:\n",
    "        node_dic[parent_lab] = node.uri\n",
    "        \n",
    "    children = node.children()\n",
    "    \n",
    "    for child in children:\n",
    "        node_dic = build_constitute_node_dic(child, node_dic)\n",
    "        \n",
    "    return node_dic\n",
    "\n",
    "def build_constitute_label_dic(node, label_dic={}):\n",
    "    node_label = constitute.getEntity(uri=node.uri).bestLabel().strip()\n",
    "    if node_label not in label_dic:\n",
    "        label_dic[node_label] = node.uri\n",
    "        \n",
    "    children = node.children()\n",
    "    \n",
    "    for child in children:\n",
    "        label_dic = build_constitute_label_dic(child, label_dic)\n",
    "        \n",
    "    return label_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some functions to manipulate the Venice thesaurus\n",
    "def build_thesaurus_node_dic(node, node_dic={}):\n",
    "    parent_lab = node.get('label')\n",
    "    \n",
    "    if parent_lab and parent_lab not in node_dic:\n",
    "        parent_lab = re.sub('\\<IT[-+]\\>', '', parent_lab)\n",
    "        node_dic[parent_lab] = {'id': node['id'], 'synonyms': node['synonyms']}\n",
    "    \n",
    "    for child in node['nodes']:\n",
    "        node_dic = build_thesaurus_node_dic(child, node_dic)\n",
    "        \n",
    "    return node_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to try out various matching approaches\n",
    "\n",
    "# base class\n",
    "class MatchBase:\n",
    "    def __init__(self, reference, word2vec_dir = None):\n",
    "        import gensim\n",
    "        self.ref_list = reference\n",
    "        \n",
    "        if word2vec_dir:\n",
    "            self.word2vec_mod = gensim.models.Word2Vec.load(word2vec_dir)\n",
    "            \n",
    "        else:\n",
    "            self.word2vec_mod = None\n",
    "            \n",
    "    def _preprocess(self, term):\n",
    "        import string\n",
    "        \n",
    "        term = re.sub('[' + string.punctuation + ']', '', term)\n",
    "        term = term.lower()\n",
    "        \n",
    "        return term\n",
    "\n",
    "# matching on the node variable name\n",
    "class NodeMatch(MatchBase):\n",
    "    def str_match(self, word):\n",
    "        # just look for simple equality between node IDs (after preprocessing)\n",
    "        word = self._preprocess(word)\n",
    "        preprocessed_ref = [self._preprocess(ref) for ref in self.ref_list]\n",
    "        \n",
    "        matches = [ref for ref in preprocessed_ref if ref == word]\n",
    "        \n",
    "        return matches\n",
    "    \n",
    "    def word2vec_match(self, word, cutoff=0.5):\n",
    "        # use a pretrained word2vec model to calculate similarity\n",
    "        # treat all values over cutoff as a match\n",
    "        \n",
    "        if not self.word2vec_mod:\n",
    "            print('Be sure to load a word2vec model before using this function!')\n",
    "        else:\n",
    "            word = self._preprocess(word)\n",
    "            preprocessed_ref = [self._preprocess(ref) for ref in self.ref_list]\n",
    "            \n",
    "            sims = {}\n",
    "            \n",
    "            for ref in preprocessed_ref:\n",
    "                try:\n",
    "                    sims[ref] = self.word2vec_mod.similarity(ref, word)\n",
    "                except:\n",
    "                    sims[ref] = None\n",
    "            \n",
    "            sims = {s: sims[s] for s in sims if sims[s] and sims[s] > cutoff}\n",
    "            return sims\n",
    "        \n",
    "# matching on plain-text label\n",
    "class LabelMatch(MatchBase):\n",
    "    def word2vec_match(self, word, cutoff=0.9):\n",
    "        # use a pretrained word2vec model to generate vectors for labels and terms\n",
    "        # for multiword labels/terms, sum vectors for each term (not a great solution, but ok for testing)\n",
    "        # treat all values over cutoff as a match\n",
    "        \n",
    "        from scipy.spatial.distance import cosine\n",
    "    \n",
    "        if not self.word2vec_mod:\n",
    "            print('Be sure to load a word2vec model before using this function!')\n",
    "        else:\n",
    "            preprocessed_word = self._preprocess(word)\n",
    "            summed_word_vec = sum([self.word2vec_mod[w] for w in preprocessed_word.split()\n",
    "                                   if w in self.word2vec_mod])\n",
    "            \n",
    "            # sum() casts None to 0\n",
    "            # so, checking for int is a hack to make sure at least one token in the word was in the word2vec vocab\n",
    "            if type(summed_word_vec) != int:\n",
    "                ref_vectors = {}\n",
    "                for ref in self.ref_list:\n",
    "                    preprocessed_ref = self._preprocess(ref)\n",
    "                    summed_label = sum([self.word2vec_mod[w] for w in preprocessed_ref.split() \n",
    "                                        if w in self.word2vec_mod])\n",
    "                    \n",
    "                    # see above\n",
    "                    if type(summed_label) != int:\n",
    "                        ref_vectors[ref] = summed_label\n",
    "\n",
    "                # note cosine = distance, not similarity w/ scipy\n",
    "                sims = {ref: 1 - cosine(summed_word_vec, ref_vectors[ref]) for ref in ref_vectors}\n",
    "\n",
    "                sims = {ref: sims[ref] for ref in sims if sims[ref] > cutoff}\n",
    "            \n",
    "                return sims\n",
    "            \n",
    "            else:\n",
    "                return {}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the various helper dictionaries\n",
    "constitute_base_node = constitute.getClass('/Topics')[0]\n",
    "constitute_nodes = build_constitute_node_dic(constitute_base_node)\n",
    "constitute_labels = build_constitute_label_dic(constitute_base_node)\n",
    "\n",
    "# renaming node key in the top-level element to make recursion easier\n",
    "try:\n",
    "    thesaurus['nodes'] = thesaurus.pop('data')\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "thesaurus_nodes = build_thesaurus_node_dic(thesaurus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the two nodematch approaches\n",
    "node_match = NodeMatch(constitute_nodes, 'data/word2vec_model_200_no_stem.pydata')\n",
    "\n",
    "str_matches = []\n",
    "word2vec_node_matches = {}\n",
    "for node in thesaurus_nodes:\n",
    "    str_matches += node_match.str_match(node)\n",
    "\n",
    "    word2vec_match = node_match.word2vec_match(node)\n",
    "    if word2vec_match:\n",
    "        word2vec_node_matches[node] = word2vec_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['press',\n",
       " 'quorum',\n",
       " 'elections',\n",
       " 'budget',\n",
       " 'religion',\n",
       " 'language',\n",
       " 'motto',\n",
       " 'immunity',\n",
       " 'flag',\n",
       " 'finance',\n",
       " 'opinion',\n",
       " 'executive',\n",
       " 'evidence']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple string match on node variable names works, but very limiting\n",
    "str_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 38\n",
      "--------\n",
      "Quorum {'quorum': 1.0}\n",
      "\n",
      "\n",
      "Press {'press': 0.99999999999999978}\n",
      "\n",
      "\n",
      "Descent {'citizenship': 0.51500973580595866}\n",
      "\n",
      "\n",
      "Religion {'language': 0.50396666816307301, 'religion': 1.0000000000000002}\n",
      "\n",
      "\n",
      "Evidence {'evidence': 1.0000000000000002}\n",
      "\n",
      "\n",
      "Elections {'elections': 1.0000000000000002}\n",
      "\n",
      "\n",
      "Sources {'solid': 0.52187535536213903, 'artists': 0.50256415038372437, 'income': 0.58208191228157891}\n",
      "\n",
      "\n",
      "Opinions {'religion': 0.5335791064221963}\n",
      "\n",
      "\n",
      "Subsidiarity {'artists': 0.58169680661190515, 'leisure': 0.5057359604314462}\n",
      "\n",
      "\n",
      "Gender {'religion': 0.53510538839770427}\n",
      "\n",
      "\n",
      "Sessions {'session': 0.72443373048092163}\n",
      "\n",
      "\n",
      "Equity {'artists': 0.55882544590066585, 'leisure': 0.51139734863407682}\n",
      "\n",
      "\n",
      "Proportionality {'artists': 0.54255512659428107}\n",
      "\n",
      "\n",
      "Minors {'artists': 0.63674318019057807, 'cruelty': 0.60806843932744281, 'juvenile': 0.50801678725797683, 'shelter': 0.57942234718381536}\n",
      "\n",
      "\n",
      "Election {'elections': 0.64403200109000447}\n",
      "\n",
      "\n",
      "Budget {'budget': 0.99999999999999967}\n",
      "\n",
      "\n",
      "Universities {'artists': 0.57445536425797761, 'science': 0.51662112094278811}\n",
      "\n",
      "\n",
      "Languages {'language': 0.66796884007939106}\n",
      "\n",
      "\n",
      "Admissibility {'jury': 0.50002017610264649}\n",
      "\n",
      "\n",
      "Characteristics {'solid': 0.52293000243150789, 'artists': 0.60917408099020354, 'shelter': 0.51018075756195369, 'leisure': 0.53072226367276587}\n",
      "\n",
      "\n",
      "Correspondence {'privacy': 0.73245220338826944}\n",
      "\n",
      "\n",
      "Language {'language': 1.0, 'religion': 0.50396666816307301}\n",
      "\n",
      "\n",
      "Implementation {'enforcement': 0.51563595451804933}\n",
      "\n",
      "\n",
      "Effects {'amparo': 0.51646438714801035}\n",
      "\n",
      "\n",
      "Flag {'motto': 0.55580798315594293, 'arms': 0.54487966301844304, 'anthem': 0.84562744610617557, 'flag': 1.0}\n",
      "\n",
      "\n",
      "Taxation {'tax': 0.55960877467954795}\n",
      "\n",
      "\n",
      "Immunity {'immunity': 1.0}\n",
      "\n",
      "\n",
      "Opinion {'opinion': 1.0}\n",
      "\n",
      "\n",
      "Costs {'income': 0.51825770722997766}\n",
      "\n",
      "\n",
      "Finance {'finance': 0.99999999999999978}\n",
      "\n",
      "\n",
      "Foreigners {'asylum': 0.52807246732580326, 'artists': 0.51293563607890402, 'slave': 0.54842999886666566}\n",
      "\n",
      "\n",
      "Equality {'equal': 0.51332090408235009, 'dignity': 0.50960294834118935}\n",
      "\n",
      "\n",
      "Race {'religion': 0.64135900807386692}\n",
      "\n",
      "\n",
      "Executive {'executive': 1.0}\n",
      "\n",
      "\n",
      "Employment {'work': 0.50108377983374963}\n",
      "\n",
      "\n",
      "Types {'cruelty': 0.54051006852367023, 'artists': 0.54955843979581276}\n",
      "\n",
      "\n",
      "Democracy {'dignity': 0.53929983623889455}\n",
      "\n",
      "\n",
      "Motto {'motto': 0.99999999999999989, 'flag': 0.55580798315594293, 'anthem': 0.56877491481239872}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# word2vec on variable names works, but only works for labels that are in-vocab (e.g. \"judcrts4\" won't work)\n",
    "# likely would perform better with a more broadly-trained model\n",
    "# cutoff value optimization?\n",
    "\n",
    "print('Number of matches:', len(word2vec_node_matches))\n",
    "print('--------')\n",
    "for node in word2vec_node_matches:\n",
    "    print(node, word2vec_node_matches[node])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the label match approach\n",
    "label_match = LabelMatch(constitute_labels, 'data/word2vec_model_200_no_stem.pydata')\n",
    "\n",
    "word2vec_label_matches = {}\n",
    "for node in thesaurus_nodes:\n",
    "    word2vec_match = label_match.word2vec_match(node)\n",
    "    if word2vec_match:\n",
    "        word2vec_label_matches[node] = word2vec_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matches: 50\n",
      "--------\n",
      "Supreme court {'Supreme court selection': 0.90037642165321397, 'Supreme Court': 1.0000000637617144}\n",
      "\n",
      "\n",
      "Right to strike {'Right to strike': 0.99999993040035029, 'Right to marry': 0.93834152957881189}\n",
      "\n",
      "\n",
      "Right to examine witnesses {'Right to examine evidence/ witnesses': 0.95642475482647193}\n",
      "\n",
      "\n",
      "Right to property {'Right to transfer property': 0.90977353764079061}\n",
      "\n",
      "\n",
      "Religion {'Religion': 1.0000000508991531}\n",
      "\n",
      "\n",
      "Campaign financing {'Campaign financing': 0.99999999655654837}\n",
      "\n",
      "\n",
      "Right to culture {'Right to culture': 0.99999987631324583}\n",
      "\n",
      "\n",
      "Political parties {'Prohibited political parties': 0.91217097770310263, 'Preferred political parties': 0.98159481404626348, 'Political Parties': 0.99999993103685325}\n",
      "\n",
      "\n",
      "Right of petition {'Right of petition': 1.0000001293862277}\n",
      "\n",
      "\n",
      "Right to life {'Right to life': 0.99999993500477657}\n",
      "\n",
      "\n",
      "Administrative courts {'Administrative Courts': 0.99999996484490739}\n",
      "\n",
      "\n",
      "Banning of political parties {'Preferred political parties': 0.94257587757580841, 'Political Parties': 0.96286423422518752}\n",
      "\n",
      "\n",
      "Structure of the State {'Structure of the State': 1.0000000822456498}\n",
      "\n",
      "\n",
      "Language {'Language': 1.0000000800361104}\n",
      "\n",
      "\n",
      "Right to work {'Right to work': 0.99999995092275029, 'Right to shelter': 0.91873977727706069}\n",
      "\n",
      "\n",
      "Freedom of association {'Freedom of association': 1.0000000155611244}\n",
      "\n",
      "\n",
      "Right to private life {'Right to life': 0.90400554686796841}\n",
      "\n",
      "\n",
      "Right to housing {'Right to shelter': 0.95145736230604172}\n",
      "\n",
      "\n",
      "Right to health {'Right to health care': 0.93087704992464648}\n",
      "\n",
      "\n",
      "Freedom of expression {'Freedom of expression': 0.99999992567199414, 'Freedom of opinion/thought/conscience': 0.90960165159869655, 'Freedom of press': 0.91340782591272696}\n",
      "\n",
      "\n",
      "Freedom of movement {'Freedom of movement': 0.99999990407625661}\n",
      "\n",
      "\n",
      "Right to information {'Right to information': 1.0000000227777717}\n",
      "\n",
      "\n",
      "Freedom of conscience {'Freedom of expression': 0.91198127134177775, 'Freedom of opinion/thought/conscience': 0.90670733582358776}\n",
      "\n",
      "\n",
      "Prohibition of arbitrariness {'Prohibition of double jeopardy': 0.91474098211615795}\n",
      "\n",
      "\n",
      "Right to family life {'Right to life': 0.93568909252418286}\n",
      "\n",
      "\n",
      "International treaties {'Treaties': 0.92948876394574265}\n",
      "\n",
      "\n",
      "European Central Bank {'Central bank': 0.91301416194193485}\n",
      "\n",
      "\n",
      "Elections {'Elections': 0.99999986920196748}\n",
      "\n",
      "\n",
      "Freedom of assembly {'Freedom of assembly': 0.9999999463086422}\n",
      "\n",
      "\n",
      "Right to self-determination {'Right to shelter': 0.93309634142323505, 'Right to marry': 0.93944211874671069}\n",
      "\n",
      "\n",
      "Basic principles {'Basic Principles': 1.0000000079516849}\n",
      "\n",
      "\n",
      "Quasi-constitutional legislation {'Legislation': 0.99999994125692659}\n",
      "\n",
      "\n",
      "Principles and methods {'Principles and Symbols': 0.90549738910254218}\n",
      "\n",
      "\n",
      "Right to emigrate {'Right to privacy': 0.90276798971319405, 'Right to counsel': 0.9126987877210111, 'Right to work': 0.90781111633810407, 'Right to strike': 0.93653337709117479, 'Right to shelter': 0.94440410666438257, 'Right to marry': 0.9750930729347359, 'Right to amparo': 0.93585844382331962}\n",
      "\n",
      "\n",
      "Right to citizenship or nationality {'Right to renounce citizenship': 0.90587237733579218}\n",
      "\n",
      "\n",
      "Civil and political rights {'Civil and Political Rights': 0.99999992606434462}\n",
      "\n",
      "\n",
      "Head of State {'Head of state replacement': 0.95781408503236642, 'Head of State': 0.99999996781677725}\n",
      "\n",
      "\n",
      "The civil service {'Civil service recruitment': 0.90824097437230089}\n",
      "\n",
      "\n",
      "Central bank {'Central bank': 1.000000023261278}\n",
      "\n",
      "\n",
      "National emblem {'National anthem': 0.91034108175094819}\n",
      "\n",
      "\n",
      "Secret ballot {'Secret ballot': 1.0000000570994394}\n",
      "\n",
      "\n",
      "Freedom to teach {'Right to academic freedom': 0.90979227243984517}\n",
      "\n",
      "\n",
      "Law-making procedure {'Veto override procedure': 0.90854767994737906}\n",
      "\n",
      "\n",
      "National anthem {'National flag': 0.93151134405630442, 'National anthem': 1.0000000285995287}\n",
      "\n",
      "\n",
      "Right to counsel {'Right to counsel': 0.9999999463261926, 'Right to marry': 0.90479638336983415}\n",
      "\n",
      "\n",
      "Ombudsman {'Ombudsman': 0.99999992274859917}\n",
      "\n",
      "\n",
      "Prohibition of torture and inhuman and degrading treatment {'Prohibition of cruel treatment': 0.93770811995994929}\n",
      "\n",
      "\n",
      "Ordinary courts {'Ordinary Courts': 1.0000001456895935}\n",
      "\n",
      "\n",
      "Executive {'Executive': 0.99999994113039825}\n",
      "\n",
      "\n",
      "Race {'Race and Ethnicity': 0.94152528028509719}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Not bad, though still not a ton of matches\n",
    "# again, cutoff optimization?\n",
    "\n",
    "print('Number of matches:', len(word2vec_label_matches))\n",
    "print('--------')\n",
    "for label in word2vec_label_matches:\n",
    "    print(label, word2vec_label_matches[label])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of overlaps: 5\n"
     ]
    }
   ],
   "source": [
    "# Interestingly, pretty different information in two word2vec approaches\n",
    "# combined, this gets ~10% of total\n",
    "print('Number of overlaps:', sum([k in word2vec_label_matches for k in word2vec_node_matches]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
